{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f907c35",
   "metadata": {},
   "source": [
    "# MIT BIH heart beat classification model for heartbeats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install neurokit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8922b604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded functions\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "%run Functions.ipynb\n",
    "%run FeaturesFunctions.ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70150025",
   "metadata": {},
   "source": [
    "First we need to create a training file with all of the annotated files in order\n",
    "File name: 1 csv for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec032095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AnnotatedFileNames=[*range(100,125)]+[*range(200,235)]\n",
    "remove=[110,113,120,204,206,211,216,218,224,225,226,227,229]\n",
    "for i in remove:\n",
    "    AnnotatedFileNames.remove(i)\n",
    "Training = pd.DataFrame(columns = ['File','Result', 'Sample#'] )\n",
    "\n",
    "\n",
    "for i in AnnotatedFileNames:\n",
    "    temp= pd.DataFrame(columns = Training.columns)\n",
    "\n",
    "    FileName =\"mitbih_database/\" + str(i)+'annotations.txt'\n",
    "    annotations = mlbeats.df_from_txt(FileName)\n",
    "    temp['Sample#']=annotations['Sample#']\n",
    "    temp['Result']=annotations['Result']\n",
    "    temp['File']= i\n",
    "    \n",
    "    Training = pd.concat([Training, temp], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "42459253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110851\n"
     ]
    }
   ],
   "source": [
    "Training.head()\n",
    "print(len(Training))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4eda0",
   "metadata": {},
   "source": [
    "Adding neurokit data and aux data to training file.ipynbThen using the nerokit library we can add feature locations to set features in the data, Filename: Adding neurokit data and aux data to training file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "820c0209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting File 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryson\\anaconda3\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:81: NeuroKitWarning: Input does not have an `ECG_Rate` column. Will skip all rate-related features.\n",
      "  warn(\n",
      "C:\\Users\\Bryson\\anaconda3\\lib\\site-packages\\neurokit2\\ecg\\ecg_eventrelated.py:147: NeuroKitWarning: Input does not have an `ECG_Phase_Artrial` or `ECG_Phase_Ventricular` column. Will not indicate whether event onset concurs with cardiac phase.\n",
      "  warn(\n",
      "C:\\Users\\Bryson\\anaconda3\\lib\\site-packages\\neurokit2\\ecg\\ecg_eventrelated.py:170: NeuroKitWarning: Input does not have an `ECG_Quality` column. Quality of the signal is not computed.\n",
      "  warn(\n",
      "C:\\Users\\Bryson\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Bryson\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction complete\n",
      "extracting File 101\n",
      "extraction complete\n",
      "extracting File 102\n",
      "extraction complete\n",
      "extracting File 103\n",
      "extraction complete\n",
      "extracting File 104\n",
      "extraction complete\n",
      "extracting File 105\n",
      "extraction complete\n",
      "extracting File 106\n",
      "extraction complete\n",
      "extracting File 107\n",
      "extraction complete\n",
      "extracting File 108\n",
      "extraction complete\n",
      "extracting File 109\n",
      "extraction complete\n",
      "extracting File 111\n",
      "extraction complete\n",
      "extracting File 112\n",
      "extraction complete\n",
      "extracting File 114\n",
      "extraction complete\n",
      "extracting File 115\n",
      "extraction complete\n",
      "extracting File 116\n",
      "extraction complete\n",
      "extracting File 117\n",
      "extraction complete\n",
      "extracting File 118\n",
      "extraction complete\n",
      "extracting File 119\n",
      "extraction complete\n",
      "extracting File 121\n",
      "extraction complete\n",
      "extracting File 122\n",
      "extraction complete\n",
      "extracting File 123\n",
      "extraction complete\n",
      "extracting File 124\n",
      "extraction complete\n",
      "extracting File 200\n",
      "extraction complete\n",
      "extracting File 201\n",
      "extraction complete\n",
      "extracting File 202\n",
      "extraction complete\n",
      "extracting File 203\n",
      "extraction complete\n",
      "extracting File 205\n",
      "extraction complete\n",
      "extracting File 207\n",
      "extraction complete\n",
      "extracting File 208\n",
      "extraction complete\n",
      "extracting File 209\n",
      "extraction complete\n",
      "extracting File 210\n",
      "extraction complete\n",
      "extracting File 212\n",
      "extraction complete\n",
      "extracting File 213\n",
      "extraction complete\n",
      "extracting File 214\n",
      "extraction complete\n",
      "extracting File 215\n",
      "extraction complete\n",
      "extracting File 217\n",
      "extraction complete\n",
      "extracting File 219\n",
      "extraction complete\n",
      "extracting File 220\n",
      "extraction complete\n",
      "extracting File 221\n",
      "extraction complete\n",
      "extracting File 222\n",
      "extraction complete\n",
      "extracting File 223\n",
      "extraction complete\n",
      "extracting File 228\n",
      "extraction complete\n",
      "extracting File 230\n",
      "extraction complete\n",
      "extracting File 231\n",
      "extraction complete\n",
      "extracting File 232\n",
      "extraction complete\n",
      "extracting File 233\n",
      "extraction complete\n",
      "extracting File 234\n",
      "extraction complete\n"
     ]
    }
   ],
   "source": [
    "testFeatures=pd.DataFrame()\n",
    "for file in AnnotatedFileNames:\n",
    "    DATA= pd.DataFrame(np.nan, index=range(1), columns=testFeatures.columns)\n",
    "    testFeatures=pd.concat([testFeatures,DATA])\n",
    "    testFeatures=pd.concat([testFeatures,Bryson.NerokitExtraction(file)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8320ab73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>File</th>\n",
       "      <th>Result</th>\n",
       "      <th>Sample#</th>\n",
       "      <th>beat_number</th>\n",
       "      <th>ECG_R_Peaks</th>\n",
       "      <th>ECG_Q_Peaks</th>\n",
       "      <th>ECG_S_Peaks</th>\n",
       "      <th>ECG_P_Peaks</th>\n",
       "      <th>...</th>\n",
       "      <th>ECG_Q_Peaks</th>\n",
       "      <th>ECG_S_Peaks</th>\n",
       "      <th>ECG_P_Peaks</th>\n",
       "      <th>ECG_P_Onsets</th>\n",
       "      <th>ECG_P_Offsets</th>\n",
       "      <th>ECG_T_Peaks</th>\n",
       "      <th>ECG_T_Onsets</th>\n",
       "      <th>ECG_T_Offsets</th>\n",
       "      <th>ECG_R_Onsets</th>\n",
       "      <th>ECG_R_Offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>N</td>\n",
       "      <td>370</td>\n",
       "      <td>2</td>\n",
       "      <td>370.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>N</td>\n",
       "      <td>662</td>\n",
       "      <td>3</td>\n",
       "      <td>662.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>N</td>\n",
       "      <td>946</td>\n",
       "      <td>4</td>\n",
       "      <td>946.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>...</td>\n",
       "      <td>347.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100</td>\n",
       "      <td>N</td>\n",
       "      <td>1231</td>\n",
       "      <td>5</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>...</td>\n",
       "      <td>641.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100</td>\n",
       "      <td>N</td>\n",
       "      <td>1515</td>\n",
       "      <td>6</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>...</td>\n",
       "      <td>926.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>858.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>892.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index File Result Sample# beat_number  ECG_R_Peaks  ECG_Q_Peaks  \\\n",
       "0      2.0    2.0  100      N     370           2        370.0        347.0   \n",
       "1      3.0    3.0  100      N     662           3        662.0        641.0   \n",
       "2      4.0    4.0  100      N     946           4        946.0        926.0   \n",
       "3      5.0    5.0  100      N    1231           5       1231.0       1210.0   \n",
       "4      6.0    6.0  100      N    1515           6       1515.0       1493.0   \n",
       "\n",
       "   ECG_S_Peaks  ECG_P_Peaks  ...  ECG_Q_Peaks  ECG_S_Peaks  ECG_P_Peaks  \\\n",
       "0        467.0        311.0  ...          NaN          NaN          NaN   \n",
       "1        697.0        606.0  ...         55.0        174.0          NaN   \n",
       "2        971.0        886.0  ...        347.0        467.0        311.0   \n",
       "3       1323.0       1169.0  ...        641.0        697.0        606.0   \n",
       "4       1609.0       1454.0  ...        926.0        971.0        886.0   \n",
       "\n",
       "  ECG_P_Onsets  ECG_P_Offsets  ECG_T_Peaks  ECG_T_Onsets  ECG_T_Offsets  \\\n",
       "0          NaN            NaN          NaN           NaN            NaN   \n",
       "1          NaN            NaN          NaN           NaN            NaN   \n",
       "2        283.0          344.0          NaN           NaN            NaN   \n",
       "3        578.0          638.0          NaN           NaN            NaN   \n",
       "4        858.0          923.0          NaN           NaN            NaN   \n",
       "\n",
       "   ECG_R_Onsets  ECG_R_Offsets  \n",
       "0           NaN            NaN  \n",
       "1           NaN            NaN  \n",
       "2         314.0            NaN  \n",
       "3         612.0            NaN  \n",
       "4         892.0            NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NewTraining=pd.concat([NewTraining,NewFeatures],axis=1)\n",
    "Training = Training.reset_index()\n",
    "testFeatures=testFeatures.reset_index(drop=True)\n",
    "Training=pd.concat([Training,testFeatures],axis=1)\n",
    "Training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed27c0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110851\n",
      "60924\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "5.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 5",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13764/1552895266.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m#print(i,\":\",time.time()-start)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mRRLIST\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRRLIST\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ECG_R_Peaks\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mTraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ECG_R_Peaks\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mQQLIST\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQQLIST\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ECG_Q_Peaks\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mTraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ECG_Q_Peaks\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mPPLIST\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPPLIST\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ECG_P_Peaks\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mTraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ECG_P_Peaks\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 5.0"
     ]
    }
   ],
   "source": [
    "\n",
    "Training = Training.drop([\"ECG_T_Peaks\",\"ECG_T_Onsets\",\"ECG_T_Offsets\",\"ECG_R_Offsets\"],axis='columns')\n",
    "print(len(Training))\n",
    "Training.dropna(inplace=True)\n",
    "print(len(Training))\n",
    "\n",
    "\n",
    "Interval = pd.DataFrame(columns=[\"File\",\"Abnormal\",\"Result\",\"R-R Interval\",\"R Height\",\"R_Onset-Rpeak\",\"Q-Q Interval\",\"Q Height\",\"P_Onset-P_Offset\",\"P Height\",\"P-P Interval\",\"P_Onset-Ppeak\"])\n",
    "RRLIST=np.array([])\n",
    "QQLIST=np.array([])\n",
    "R_Height=np.array([])\n",
    "Q_Height=np.array([]) \n",
    "P_Height=np.array([])\n",
    "Ron_RP=np.array([])\n",
    "Pon_PP=np.array([])\n",
    "Pon_Poff=np.array([])\n",
    "PPLIST=np.array([])\n",
    "Abnormal=np.array([])\n",
    "Result=np.array([])\n",
    "FILES=np.array([])\n",
    "y=2\n",
    "FileNumber=Training[\"File\"][y]\n",
    "RAWFile= pd.read_csv(\"mitbih_database/\"+str(FileNumber)+\".csv\")\n",
    "\n",
    "for i in Training[\"index\"][:-1]:\n",
    "    #FileNumber=Training[\"File\"][i]\n",
    "    #df=pd.DataFrame(columns=Interval.columns)\n",
    "    #RAWFile= pd.read_csv(\"mitbih_database/\"+str(FileNumber)+\".csv\")\n",
    "    \n",
    "    if (i-y>1):\n",
    "        y=i\n",
    "        continue\n",
    "    if Training[\"Result\"][i]=='N':\n",
    "        Abnormal=np.append(Abnormal,0)\n",
    "    else:\n",
    "        Abnormal=np.append(Abnormal,1)\n",
    "    if (Training[\"File\"][i] != FileNumber):\n",
    "        print(\"Reading File\",FileNumber)\n",
    "        FileNumber=Training[\"File\"][i]\n",
    "        RAWFile= pd.read_csv(\"mitbih_database/\"+str(FileNumber)+\".csv\")\n",
    "    #if (i%100 ==0):\n",
    "        #print(i,\":\",time.time()-start)\n",
    "\n",
    "    RRLIST=np.append(RRLIST,Training[\"ECG_R_Peaks\"][i]-Training[\"ECG_R_Peaks\"][y])\n",
    "    QQLIST=np.append(QQLIST,Training[\"ECG_Q_Peaks\"][i]-Training[\"ECG_Q_Peaks\"][y])\n",
    "    PPLIST=np.append(PPLIST,Training[\"ECG_P_Peaks\"][i]-Training[\"ECG_P_Peaks\"][y])\n",
    "    R_Height=np.append(R_Height,RAWFile[RAWFile.columns[1]][Training[\"ECG_R_Peaks\"][i]])#\n",
    "    Q_Height=np.append(Q_Height,RAWFile[RAWFile.columns[1]][Training[\"ECG_Q_Peaks\"][i]])#\n",
    "    P_Height=np.append(P_Height,RAWFile[RAWFile.columns[1]][Training[\"ECG_P_Peaks\"][i]])#\n",
    "    Ron_RP=np.append(Ron_RP,Training[\"ECG_R_Peaks\"][i]-Training[\"ECG_R_Onsets\"][i])\n",
    "    Pon_PP=np.append(Pon_PP,Training[\"ECG_P_Peaks\"][i]-Training[\"ECG_P_Onsets\"][i])\n",
    "    Pon_Poff=np.append(Pon_Poff,Training[\"ECG_P_Offsets\"][i]-Training[\"ECG_P_Onsets\"][i])\n",
    "    Result=np.append(Result,Training[\"Result\"][i])\n",
    "    FILES=np.append(FILES,FileNumber)\n",
    "    \n",
    "    y=i\n",
    "\n",
    "Interval[\"R-R Interval\"]=RRLIST\n",
    "Interval[\"Q-Q Interval\"]=QQLIST\n",
    "Interval[\"P-P Interval\"]=PPLIST\n",
    "Interval[\"R_Onset-Rpeak\"]=Ron_RP\n",
    "Interval[\"P_Onset-Ppeak\"]=Pon_PP\n",
    "Interval[\"P_Onset-P_Offset\"]=Pon_Poff\n",
    "Interval[\"R Height\"]=R_Height#\n",
    "Interval[\"Q Height\"]=Q_Height#\n",
    "Interval[\"P Height\"]=P_Height#\n",
    "Interval[\"File\"]=FILES\n",
    "Interval[\"Abnormal\"]=Abnormal\n",
    "Interval[\"Result\"]=Result\n",
    "\n",
    "print(\"Length of DataFrame\",len(Interval))\n",
    "Interval.head(10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7bc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interval.dropna(inplace=True)\n",
    "Interval.head()\n",
    "\n",
    "#creatin\n",
    "model1 = tree.DecisionTreeClassifier()\n",
    "\n",
    "inputs = Interval.drop([\"Result\",\"Abnormal\"],axis='columns')\n",
    "Target = Interval[[\"Abnormal\"]]\n",
    "\n",
    "\n",
    "\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(inputs, Target,test_size=0.3)\n",
    "\n",
    "model1.fit(X=x_train1,y=y_train1)\n",
    "print(model1.score(x_test1,y_test1),\"Regular\")\n",
    "print(roc_auc_score(y_test1, model1.predict(x_test1)),\"AUC1\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac99a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
