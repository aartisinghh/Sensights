{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f907c35",
   "metadata": {},
   "source": [
    "# MIT BIH heart beat classification model for heartbeats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install neurokit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8922b604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded functions\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "%run Functions.ipynb\n",
    "%run FeaturesFunctions.ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70150025",
   "metadata": {},
   "source": [
    "First we need to create a training file with all of the annotated files in order\n",
    "File name: 1 csv for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec032095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AnnotatedFileNames=[*range(100,125)]+[*range(200,235)]\n",
    "remove=[110,113,120,204,206,211,216,218,224,225,226,227,229]\n",
    "for i in remove:\n",
    "    AnnotatedFileNames.remove(i)\n",
    "Training = pd.DataFrame(columns = ['File','Result', 'Sample#'] )\n",
    "\n",
    "AnnotatedFileNames=AnnotatedFileNames[:5]\n",
    "for i in AnnotatedFileNames:\n",
    "    temp= pd.DataFrame(columns = Training.columns)\n",
    "\n",
    "    FileName =\"mitbih_database/\" + str(i)+'annotations.txt'\n",
    "    annotations = mlbeats.df_from_txt(FileName)\n",
    "    temp['Sample#']=annotations['Sample#']\n",
    "    temp['Result']=annotations['Result']\n",
    "    temp['File']= i\n",
    "    \n",
    "    Training = pd.concat([Training, temp], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42459253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10742\n"
     ]
    }
   ],
   "source": [
    "Training.head()\n",
    "print(len(Training))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4eda0",
   "metadata": {},
   "source": [
    "Adding neurokit data and aux data to training file.ipynbThen using the nerokit library we can add feature locations to set features in the data, Filename: Adding neurokit data and aux data to training file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "820c0209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting File 100\n",
      "extraction complete\n",
      "extracting File 101\n",
      "extraction complete\n",
      "extracting File 102\n",
      "extraction complete\n",
      "extracting File 103\n",
      "extraction complete\n",
      "extracting File 104\n",
      "extraction complete\n"
     ]
    }
   ],
   "source": [
    "testFeatures=pd.DataFrame()\n",
    "for file in AnnotatedFileNames:\n",
    "    DATA= pd.DataFrame(np.nan, index=range(1), columns=testFeatures.columns)\n",
    "    testFeatures=pd.concat([testFeatures,DATA])\n",
    "    testFeatures=pd.concat([testFeatures,Bryson.NerokitExtraction(file)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8320ab73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>File</th>\n",
       "      <th>Result</th>\n",
       "      <th>Sample#</th>\n",
       "      <th>beat_number</th>\n",
       "      <th>ECG_R_Peaks</th>\n",
       "      <th>ECG_Q_Peaks</th>\n",
       "      <th>ECG_S_Peaks</th>\n",
       "      <th>ECG_P_Peaks</th>\n",
       "      <th>ECG_P_Onsets</th>\n",
       "      <th>ECG_P_Offsets</th>\n",
       "      <th>ECG_T_Peaks</th>\n",
       "      <th>ECG_T_Onsets</th>\n",
       "      <th>ECG_T_Offsets</th>\n",
       "      <th>ECG_R_Onsets</th>\n",
       "      <th>ECG_R_Offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>+</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>N</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>N</td>\n",
       "      <td>370</td>\n",
       "      <td>2</td>\n",
       "      <td>370.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>N</td>\n",
       "      <td>662</td>\n",
       "      <td>3</td>\n",
       "      <td>662.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>N</td>\n",
       "      <td>946</td>\n",
       "      <td>4</td>\n",
       "      <td>946.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>858.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>892.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index File Result Sample# beat_number  ECG_R_Peaks  ECG_Q_Peaks  \\\n",
       "0      0  100      +      18         NaN          NaN          NaN   \n",
       "1      1  100      N      77           1         77.0         55.0   \n",
       "2      2  100      N     370           2        370.0        347.0   \n",
       "3      3  100      N     662           3        662.0        641.0   \n",
       "4      4  100      N     946           4        946.0        926.0   \n",
       "\n",
       "   ECG_S_Peaks  ECG_P_Peaks  ECG_P_Onsets  ECG_P_Offsets  ECG_T_Peaks  \\\n",
       "0          NaN          NaN           NaN            NaN          NaN   \n",
       "1        174.0          NaN           NaN            NaN          NaN   \n",
       "2        467.0        311.0         283.0          344.0          NaN   \n",
       "3        697.0        606.0         578.0          638.0          NaN   \n",
       "4        971.0        886.0         858.0          923.0          NaN   \n",
       "\n",
       "   ECG_T_Onsets  ECG_T_Offsets  ECG_R_Onsets  ECG_R_Offsets  \n",
       "0           NaN            NaN           NaN            NaN  \n",
       "1           NaN            NaN           NaN            NaN  \n",
       "2           NaN            NaN         314.0            NaN  \n",
       "3           NaN            NaN         612.0            NaN  \n",
       "4           NaN            NaN         892.0            NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NewTraining=pd.concat([NewTraining,NewFeatures],axis=1)\n",
    "Training = Training.reset_index(drop=True)\n",
    "testFeatures=testFeatures.reset_index(drop=True)\n",
    "Training=pd.concat([Training,testFeatures],axis=1)\n",
    "Training = Training.reset_index()\n",
    "Training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "376edea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10742\n",
      "7188\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Training = Training.drop([\"ECG_T_Peaks\",\"ECG_T_Onsets\",\"ECG_T_Offsets\",\"ECG_R_Offsets\"],axis='columns')\n",
    "print(len(Training))\n",
    "Training.dropna(inplace=True)\n",
    "print(len(Training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8faca6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interval = pd.DataFrame(columns=[\"File\",\"Abnormal\",\"Result\",\"R-R Interval\",\"R Height\",\"R_Onset-Rpeak\",\"Q-Q Interval\",\"Q Height\",\"P_Onset-P_Offset\",\"P Height\",\"P-P Interval\",\"P_Onset-Ppeak\"])\n",
    "RRLIST=np.array([])\n",
    "QQLIST=np.array([])\n",
    "R_Height=np.array([])\n",
    "Q_Height=np.array([]) \n",
    "P_Height=np.array([])\n",
    "Ron_RP=np.array([])\n",
    "Pon_PP=np.array([])\n",
    "Pon_Poff=np.array([])\n",
    "PPLIST=np.array([])\n",
    "Abnormal=np.array([])\n",
    "Result=np.array([])\n",
    "FILES=np.array([])\n",
    "y=2\n",
    "FileNumber=Training[\"File\"][y]\n",
    "RAWFile= pd.read_csv(\"mitbih_database/\"+str(FileNumber)+\".csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "381be221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed27c0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading File 100\n",
      "Reading File 101\n",
      "Reading File 102\n",
      "Reading File 103\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (16978) does not match length of index (6585)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12476/893817365.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mInterval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"R-R Interval\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRRLIST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Q-Q Interval\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mQQLIST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"P-P Interval\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPPLIST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \"\"\"\n\u001b[1;32m-> 3784\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3786\u001b[0m         if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4509\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (16978) does not match length of index (6585)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in Training[\"index\"][:-1]:\n",
    "    if (i-y>1):\n",
    "        y=i\n",
    "        continue\n",
    "    if Training[\"Result\"][i]=='N':\n",
    "        Abnormal=np.append(Abnormal,0)\n",
    "    else:\n",
    "        Abnormal=np.append(Abnormal,1)\n",
    "    if (Training[\"File\"][i] != FileNumber):\n",
    "        print(\"Reading File\",FileNumber)\n",
    "        FileNumber=Training[\"File\"][i]\n",
    "        RAWFile= pd.read_csv(\"mitbih_database/\"+str(FileNumber)+\".csv\")\n",
    "        \n",
    "    RRLIST=np.append(RRLIST,Training[\"ECG_R_Peaks\"][i]-Training[\"ECG_R_Peaks\"][y])\n",
    "    QQLIST=np.append(QQLIST,Training[\"ECG_Q_Peaks\"][i]-Training[\"ECG_Q_Peaks\"][y])\n",
    "    PPLIST=np.append(PPLIST,Training[\"ECG_P_Peaks\"][i]-Training[\"ECG_P_Peaks\"][y])\n",
    "    R_Height=np.append(R_Height,RAWFile[RAWFile.columns[1]][Training[\"ECG_R_Peaks\"][i]])#\n",
    "    Q_Height=np.append(Q_Height,RAWFile[RAWFile.columns[1]][Training[\"ECG_Q_Peaks\"][i]])#\n",
    "    P_Height=np.append(P_Height,RAWFile[RAWFile.columns[1]][Training[\"ECG_P_Peaks\"][i]])#\n",
    "    Ron_RP=np.append(Ron_RP,Training[\"ECG_R_Peaks\"][i]-Training[\"ECG_R_Onsets\"][i])\n",
    "    Pon_PP=np.append(Pon_PP,Training[\"ECG_P_Peaks\"][i]-Training[\"ECG_P_Onsets\"][i])\n",
    "    Pon_Poff=np.append(Pon_Poff,Training[\"ECG_P_Offsets\"][i]-Training[\"ECG_P_Onsets\"][i])\n",
    "    Result=np.append(Result,Training[\"Result\"][i])\n",
    "    FILES=np.append(FILES,FileNumber)\n",
    "    \n",
    "    y=i\n",
    "\n",
    "Interval[\"R-R Interval\"]=RRLIST\n",
    "Interval[\"Q-Q Interval\"]=QQLIST\n",
    "Interval[\"P-P Interval\"]=PPLIST\n",
    "Interval[\"R_Onset-Rpeak\"]=Ron_RP\n",
    "Interval[\"P_Onset-Ppeak\"]=Pon_PP\n",
    "Interval[\"P_Onset-P_Offset\"]=Pon_Poff\n",
    "Interval[\"R Height\"]=R_Height#\n",
    "Interval[\"Q Height\"]=Q_Height#\n",
    "Interval[\"P Height\"]=P_Height#\n",
    "Interval[\"File\"]=FILES\n",
    "Interval[\"Abnormal\"]=Abnormal\n",
    "Interval[\"Result\"]=Result\n",
    "\n",
    "print(\"Length of DataFrame\",len(Interval))\n",
    "Interval.head(10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd337f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e7bc64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6585\n",
      "6585\n",
      "0.992914979757085 Regular\n",
      "0.9633011099176513 AUC1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creatin\n",
    "model1 = tree.DecisionTreeClassifier()\n",
    "\n",
    "inputs = Interval.drop([\"Result\",\"Abnormal\"],axis='columns')\n",
    "Target = Interval[[\"Abnormal\"]]\n",
    "\n",
    "\n",
    "\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(inputs, Target,test_size=0.3)\n",
    "\n",
    "model1.fit(X=x_train1,y=y_train1)\n",
    "print(model1.score(x_test1,y_test1),\"Regular\")\n",
    "print(roc_auc_score(y_test1, model1.predict(x_test1)),\"AUC1\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac99a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43750e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
