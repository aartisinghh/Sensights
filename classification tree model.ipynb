{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f907c35",
   "metadata": {},
   "source": [
    "# MIT BIH heart beat classification model for heartbeats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81f81ee",
   "metadata": {},
   "source": [
    "The libary used to collect features from raw ECG data is the neurokit.p library which is used in this project to find the locations of important parts of each ecg wave including r-peak, p-peak,q-peak,r-onset,p-onset,p-offset,q-onset,q-offset. Being as this library does not come with python it must be installed to use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e9b8037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement neurokit.py\n",
      "ERROR: No matching distribution found for neurokit.py\n"
     ]
    }
   ],
   "source": [
    "pip install neurokit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8922b604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded functions\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "%run Functions.ipynb\n",
    "%run FeaturesFunctions.ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70150025",
   "metadata": {},
   "source": [
    "First we need to create a training file with all of the annotated files in order. the files range from 100-235 not inclusive, the file 113 does not work with the Neurokit library so it was excluded from the model training.\n",
    "File name: 1 csv for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec032095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AnnotatedFileNames=[*range(100,125)]+[*range(200,235)]\n",
    "remove=[110,113,120,204,206,211,216,218,224,225,226,227,229]\n",
    "for i in remove:\n",
    "    AnnotatedFileNames.remove(i)\n",
    "Training = pd.DataFrame(columns = ['File','Result', 'Sample#'] )\n",
    "\n",
    "for i in AnnotatedFileNames:\n",
    "    temp= pd.DataFrame(columns = Training.columns)\n",
    "\n",
    "    FileName =\"mitbih_database/\" + str(i)+'annotations.txt'\n",
    "    annotations = mlbeats.df_from_txt(FileName)\n",
    "    temp['Sample#']=annotations['Sample#']\n",
    "    temp['Result']=annotations['Result']\n",
    "    temp['File']= i\n",
    "    \n",
    "    Training = pd.concat([Training, temp], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4eda0",
   "metadata": {},
   "source": [
    "Adding neurokit data and aux data to training file.ipynbThen using the nerokit library we can add feature locations to set features in the data, Filename: Adding neurokit data and aux data to training file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c0209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting File 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryso\\anaconda3\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:81: NeuroKitWarning: Input does not have an `ECG_Rate` column. Will skip all rate-related features.\n",
      "  warn(\n",
      "C:\\Users\\bryso\\anaconda3\\lib\\site-packages\\neurokit2\\ecg\\ecg_eventrelated.py:147: NeuroKitWarning: Input does not have an `ECG_Phase_Artrial` or `ECG_Phase_Ventricular` column. Will not indicate whether event onset concurs with cardiac phase.\n",
      "  warn(\n",
      "C:\\Users\\bryso\\anaconda3\\lib\\site-packages\\neurokit2\\ecg\\ecg_eventrelated.py:170: NeuroKitWarning: Input does not have an `ECG_Quality` column. Quality of the signal is not computed.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "testFeatures=pd.DataFrame()\n",
    "for file in AnnotatedFileNames:\n",
    "    DATA= pd.DataFrame(np.nan, index=range(1), columns=testFeatures.columns)\n",
    "    testFeatures=pd.concat([testFeatures,DATA])\n",
    "    testFeatures=pd.concat([testFeatures,Bryson.NerokitExtraction(file)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731ea986",
   "metadata": {},
   "source": [
    "We must then add the test features to the previously created training file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NewTraining=pd.concat([NewTraining,NewFeatures],axis=1)\n",
    "Training = Training.reset_index(drop=True)\n",
    "testFeatures=testFeatures.reset_index(drop=True)\n",
    "Training=pd.concat([Training,testFeatures],axis=1)\n",
    "Training = Training.reset_index()\n",
    "Training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86679d3",
   "metadata": {},
   "source": [
    "Due to the large amount of NaN values in the ECG_T_Peaks, ECG_T_Onsets ,ECG_T_Offsets ,and ECG_R_Offsets columns they are removed from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376edea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Training = Training.drop([\"ECG_T_Peaks\",\"ECG_T_Onsets\",\"ECG_T_Offsets\",\"ECG_R_Offsets\"],axis='columns')\n",
    "print(len(Training))\n",
    "Training.dropna(inplace=True)\n",
    "print(len(Training))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f5fc3",
   "metadata": {},
   "source": [
    "Now, Interval data is collected from the time data to get useful information to build the model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faca6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interval = pd.DataFrame(columns=[\"File\",\"Abnormal\",\"Result\",\"R-R Interval\",\"R Height\",\"R_Onset-Rpeak\",\"Q-Q Interval\",\"Q Height\",\"P_Onset-P_Offset\",\"P Height\",\"P-P Interval\",\"P_Onset-Ppeak\"])\n",
    "RRLIST=np.array([])\n",
    "QQLIST=np.array([])\n",
    "R_Height=np.array([])\n",
    "Q_Height=np.array([]) \n",
    "P_Height=np.array([])\n",
    "Ron_RP=np.array([])\n",
    "Pon_PP=np.array([])\n",
    "Pon_Poff=np.array([])\n",
    "PPLIST=np.array([])\n",
    "Abnormal=np.array([])\n",
    "Result=np.array([])\n",
    "FILES=np.array([])\n",
    "y=2\n",
    "FileNumber=Training[\"File\"][y]\n",
    "RAWFile= pd.read_csv(\"mitbih_database/\"+str(FileNumber)+\".csv\")\n",
    "\n",
    "\n",
    "for i in Training[\"index\"][:-1]:\n",
    "    if (i-y>1):\n",
    "        y=i\n",
    "        continue\n",
    "    if Training[\"Result\"][i]=='N':\n",
    "        Abnormal=np.append(Abnormal,0)\n",
    "    else:\n",
    "        Abnormal=np.append(Abnormal,1)\n",
    "    if (Training[\"File\"][i] != FileNumber):\n",
    "        print(\"Reading File\",FileNumber)\n",
    "        FileNumber=Training[\"File\"][i]\n",
    "        RAWFile= pd.read_csv(\"mitbih_database/\"+str(FileNumber)+\".csv\")\n",
    "        \n",
    "    RRLIST=np.append(RRLIST,Training[\"ECG_R_Peaks\"][i]-Training[\"ECG_R_Peaks\"][y])\n",
    "    QQLIST=np.append(QQLIST,Training[\"ECG_Q_Peaks\"][i]-Training[\"ECG_Q_Peaks\"][y])\n",
    "    PPLIST=np.append(PPLIST,Training[\"ECG_P_Peaks\"][i]-Training[\"ECG_P_Peaks\"][y])\n",
    "    R_Height=np.append(R_Height,RAWFile[RAWFile.columns[1]][Training[\"ECG_R_Peaks\"][i]])#\n",
    "    Q_Height=np.append(Q_Height,RAWFile[RAWFile.columns[1]][Training[\"ECG_Q_Peaks\"][i]])#\n",
    "    P_Height=np.append(P_Height,RAWFile[RAWFile.columns[1]][Training[\"ECG_P_Peaks\"][i]])#\n",
    "    Ron_RP=np.append(Ron_RP,Training[\"ECG_R_Peaks\"][i]-Training[\"ECG_R_Onsets\"][i])\n",
    "    Pon_PP=np.append(Pon_PP,Training[\"ECG_P_Peaks\"][i]-Training[\"ECG_P_Onsets\"][i])\n",
    "    Pon_Poff=np.append(Pon_Poff,Training[\"ECG_P_Offsets\"][i]-Training[\"ECG_P_Onsets\"][i])\n",
    "    Result=np.append(Result,Training[\"Result\"][i])\n",
    "    FILES=np.append(FILES,FileNumber)\n",
    "    \n",
    "    y=i\n",
    "\n",
    "Interval[\"R-R Interval\"]=RRLIST\n",
    "Interval[\"Q-Q Interval\"]=QQLIST\n",
    "Interval[\"P-P Interval\"]=PPLIST\n",
    "Interval[\"R_Onset-Rpeak\"]=Ron_RP\n",
    "Interval[\"P_Onset-Ppeak\"]=Pon_PP\n",
    "Interval[\"P_Onset-P_Offset\"]=Pon_Poff\n",
    "Interval[\"R Height\"]=R_Height#\n",
    "Interval[\"Q Height\"]=Q_Height#\n",
    "Interval[\"P Height\"]=P_Height#\n",
    "Interval[\"File\"]=FILES\n",
    "Interval[\"Abnormal\"]=Abnormal\n",
    "Interval[\"Result\"]=Result\n",
    "\n",
    "print(\"Length of DataFrame\",len(Interval))\n",
    "Interval.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ba936",
   "metadata": {},
   "source": [
    "Now a decision Tree classification model is created to descern between normal and abrnormal heartbeats, the model is then scored using regular scoring techniques along with the AUC score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7bc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tree.DecisionTreeClassifier()\n",
    "\n",
    "inputs = Interval.drop([\"Result\",\"Abnormal\"],axis='columns')\n",
    "Target = Interval[[\"Abnormal\"]]\n",
    "\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(inputs, Target,test_size=0.3)\n",
    "\n",
    "model1.fit(X=x_train1,y=y_train1)\n",
    "print(model1.score(x_test1,y_test1),\"Regular\")\n",
    "print(roc_auc_score(y_test1, model1.predict(x_test1)),\"AUC1\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tree.plot_tree(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2d1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
